{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inverse mass matrix in NumPyro/NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro_ext import information as information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we sample from a posterior $\\pi(x) \\propto \\mathcal{L}(x)\\,p_0(x)$ conditioned on multivariate normal likelihood\n",
    "$$\n",
    "\\mathcal{L}(x) = {1\\over\\sqrt{|2\\pi\\Sigma|}}\\,\\exp\\left[-{1\\over 2}(\\mu-x)^T\\Sigma^{-1}(\\mu-x)\\right], \\quad \\mu = \\begin{pmatrix} 2 \\\\ 1\\end{pmatrix},\\ \\Sigma = \\begin{pmatrix} 1 & 0.09 \\\\ 0.09 & 1 \\end{pmatrix}\n",
    "$$\n",
    "and a uniform, **bound** prior on $x$:\n",
    "$$\n",
    "p_0(x) = \\begin{cases}\n",
    "{1/(2x_\\mathrm{max})^2} &\\text{for}\\ |x_1| < x_\\mathrm{max}, |x_2| < x_\\mathrm{max}\\\\\n",
    "0  &\\text{otherwise}\n",
    "\\end{cases}.\n",
    "$$\n",
    "\n",
    "We use NUTS and tuned the dense inverse mass matrix $M^{-1}$. Its ideal value is the parameter covariance matrix, so we expect to find\n",
    "$$\n",
    "    M^{-1} = \\Sigma = \\mathcal{I}^{-1},\n",
    "$$\n",
    "where $\\mathcal{H}$ is the Fisher information matrix.\n",
    "Is this the case here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 4000/4000 [00:01<00:00, 3886.97it/s, 3 steps of size 7.26e-01. acc. prob=0.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "      x[0]      2.01      0.98      2.00      0.38      3.61   1582.10      1.00\n",
      "      x[1]      1.00      0.10      1.00      0.84      1.17   1514.56      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mu_true = jnp.array([2., 1.])\n",
    "cov_true = jnp.array([[1., 0.09], [0.09, 0.01]]) \n",
    "xabs_max = 10.\n",
    "\n",
    "def model():\n",
    "    x = numpyro.sample(\"x\", dist.Uniform(-xabs_max, xabs_max), sample_shape=(2,))\n",
    "    numpyro.sample(\"obs\", dist.MultivariateNormal(loc=x, covariance_matrix=cov_true), obs=mu_true) # put x in loc to make numpyro_ext informatoin work\n",
    "\n",
    "\n",
    "def run_mcmc(model, dense_mass=True, adapt_mass_matrix=True, inverse_mass_matrix=None):\n",
    "    kernel = numpyro.infer.NUTS(model, dense_mass=dense_mass, adapt_mass_matrix=adapt_mass_matrix, inverse_mass_matrix=inverse_mass_matrix)\n",
    "    mcmc = numpyro.infer.MCMC(kernel, num_warmup=2000, num_samples=2000)\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    mcmc.run(rng_key)\n",
    "    mcmc.print_summary()\n",
    "\n",
    "    return mcmc\n",
    "\n",
    "mcmc = run_mcmc(model)\n",
    "invM = mcmc.last_state.adapt_state.inverse_mass_matrix[('x',)] # this is M^{-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we evaluate the inverse Fisher information using information function in numpryo_ext. This agrees with $\\Sigma$, as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.       , 1.0000001],\n",
       "       [1.0000001, 1.0000001]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval = {'x': mu_true}\n",
    "fisher_inv = information(model, invert=True, include_prior=False, unconstrained=False)(x_eval)['x']['x']\n",
    "cov_true / fisher_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, fisher_inv does NOT agree with $M^{-1}$ tuned by NumPyro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.04571855, 0.04275488],\n",
       "       [0.04275488, 0.04069575]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invM / fisher_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? This is beacause NumPyro actually sees *unconstrained variables* $z$ that has a real support and is mapped to the constrained $x \\sim \\mathcal{U}(-x_\\mathrm{max}, x_\\mathrm{max})$.\n",
    "\n",
    "The inverse mass matrix in NumPyro NUTS is also defined w.r.t. these unconstrained variables. This can also be calculated from the same function by setting unconstrained=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.20159441, 0.3530357 ],\n",
       "       [0.35303566, 0.62925816]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval = {'x': mu_true}\n",
    "fisher_inv_unc = information(model, invert=True, include_prior=False, unconstrained=True)(x_eval)['x']['x']\n",
    "invM / fisher_inv_unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two are closer but still don't agree. The key thing here is that $M^{-1}(z)$ defined w.r.t. $z$ is no longer constant even for the gaussian $\\mathcal{L}(x)$, because the mapping $x(z)$ is non-linear.\n",
    "\n",
    "So it depends on where it's evaulated; and we need to put the value of $z$, not $x$, at which we'd like to evaulate $M^{-1}$. The value of $z$ for a given $x$ can be found as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro import handlers\n",
    "from numpyro.distributions.transforms import biject_to\n",
    "\n",
    "def to_unconstrained(model, params_constrained, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Convert constrained parameter values to their unconstrained representations\n",
    "    using the model's sample sites.\n",
    "\n",
    "    Args:\n",
    "        model (callable): A NumPyro model function.\n",
    "        params_constrained (dict): Dictionary mapping parameter names to values\n",
    "            in the *constrained* space (e.g., positive scales, simplex).\n",
    "        *args: Positional arguments passed to `model` when tracing.\n",
    "        **kwargs: Keyword arguments passed to `model` when tracing.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping parameter names to values in the\n",
    "        *unconstrained* space, suitable for use in inference algorithms\n",
    "        (e.g., HMC/NUTS).\n",
    "    \"\"\"\n",
    "    tr = handlers.trace(handlers.seed(model, 0)).get_trace(*args, **kwargs)\n",
    "    bij = {}\n",
    "    for name, site in tr.items():\n",
    "        if site[\"type\"] == \"sample\" and not site[\"is_observed\"]:\n",
    "            bij[name] = biject_to(site[\"fn\"].support)\n",
    "    # Map constrained -> unconstrained\n",
    "    z_params = {k: bij[k].inv(v) for k, v in params_constrained.items()}\n",
    "    return z_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unconstrained parameters corresponding to mu_true: {'x': Array([0.4054652 , 0.20067078], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "z_eval = to_unconstrained(model, {'x': mu_true})\n",
    "print('Unconstrained parameters corresponding to mu_true:', z_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this value of $z$, $M^{-1}$ and inverse Fisher agree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.0533552 , 1.0158558 ],\n",
       "       [1.0158558 , 0.99714756]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher_inv_unc0 = information(model, invert=True, include_prior=False, unconstrained=True)(z_eval)['x']['x']\n",
    "invM / fisher_inv_unc0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "\n",
    "- We want $M^{-1}$ to be the parameter covariance $\\Sigma$, which is the inverse of Hessian $\\mathcal{H}$.\n",
    "- But when some parameters $x$ are sampled from bounded priors, NumPyro samples from unconstrained variables $z$ that are mapped to bounded $x$. So we need to evaluate $\\Sigma$ w.r.t. $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when the mapping is identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When x is sampled from dist.Normal, mapping between $x$ and $z$ is just identity, so this complexity doesn't arise.\n",
    "\n",
    "In this case, parameter covariance evaluated for $x$ just works as $M^{-1}$. Let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 4000/4000 [00:01<00:00, 3936.08it/s, 3 steps of size 9.15e-01. acc. prob=0.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "      x[0]      1.97      0.98      1.97      0.45      3.65   2104.61      1.00\n",
      "      x[1]      1.00      0.10      1.00      0.84      1.15   2042.06      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def model_norm():\n",
    "    x = numpyro.sample(\"x\", dist.Normal(0., xabs_max), sample_shape=(2,)) # normal\n",
    "    numpyro.sample(\"obs\", dist.MultivariateNormal(loc=x, covariance_matrix=cov_true), obs=mu_true) \n",
    "\n",
    "\n",
    "def run_mcmc(model, dense_mass=True, adapt_mass_matrix=True, inverse_mass_matrix=None):\n",
    "    kernel = numpyro.infer.NUTS(model, dense_mass=dense_mass, adapt_mass_matrix=adapt_mass_matrix, inverse_mass_matrix=inverse_mass_matrix)\n",
    "    mcmc = numpyro.infer.MCMC(kernel, num_warmup=2000, num_samples=2000)\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    mcmc.run(rng_key)\n",
    "    mcmc.print_summary()\n",
    "\n",
    "    return mcmc\n",
    "\n",
    "mcmc_norm = run_mcmc(model_norm)\n",
    "invM_norm = mcmc_norm.last_state.adapt_state.inverse_mass_matrix[('x',)] # this is M^{-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = {'x': mu_true}\n",
    "fisher_inv_constrained = information(model, invert=True, include_prior=False, unconstrained=False)(x_eval)['x']['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.0130707, 1.048032 ],\n",
       "       [1.048032 , 1.0706003]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invM_norm / fisher_inv_constrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, Fisher information computed for physical parameters can be fed into NUTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jnkepler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
